{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af42f848",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JError",
     "evalue": "org.apache.spark.api.python.PythonUtils.isEncryptionEnabled does not exist in the JVM",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m cf \u001b[38;5;241m=\u001b[39m SparkConf()\n\u001b[0;32m      3\u001b[0m cf\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.submit.deployMode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m      6\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession \\\n\u001b[0;32m      7\u001b[0m \t    \u001b[38;5;241m.\u001b[39mbuilder \\\n\u001b[0;32m      8\u001b[0m \t    \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython Spark SQL basic example\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[0;32m      9\u001b[0m \t    \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.some.config.option\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msome-value\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[0;32m     10\u001b[0m \t    \u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\context.py:203\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    201\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mappName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparkHome\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpyFiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mudf_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\context.py:314\u001b[0m, in \u001b[0;36mSparkContext._do_init\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39msc()\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_javaAccumulator)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# If encryption is enabled, we need to setup a server in the jvm to read broadcast\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m# data via a socket.\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;66;03m# scala's mangled names w/ $ in them require special treatment.\u001b[39;00m\n\u001b[1;32m--> 314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encryption_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misEncryptionEnabled\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc)\n\u001b[0;32m    315\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSPARK_AUTH_SOCKET_TIMEOUT\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mgetPythonAuthSocketTimeout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc)\n\u001b[0;32m    317\u001b[0m )\n\u001b[0;32m    318\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSPARK_BUFFER_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mgetSparkBufferSize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py:1486\u001b[0m, in \u001b[0;36mJavaClass.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1483\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m get_return_value(\n\u001b[0;32m   1484\u001b[0m             answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fqn, name)\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m   1487\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m does not exist in the JVM\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fqn, name))\n",
      "\u001b[1;31mPy4JError\u001b[0m: org.apache.spark.api.python.PythonUtils.isEncryptionEnabled does not exist in the JVM"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "cf = SparkConf()\n",
    "cf.set(\"spark.submit.deployMode\",\"client\")\n",
    "sc = SparkContext.getOrCreate(cf)\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "\t    .builder \\\n",
    "\t    .appName(\"Python Spark SQL basic example\") \\\n",
    "\t    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "\t    .getOrCreate()\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d11d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# attributes: summons_number,issue_date,violation_code,violation_county,violation_description,\n",
    "#violation_location,violation_precinct,violation_time,time_first_observed,meter_number,issuer_code,\n",
    "#issuer_command,issuer_precinct,issuing_agency,plate_id,plate_type,registration_state,street_name,\n",
    "#vehicle_body_type,vehicle_color,vehicle_make,vehicle_year\n",
    "parking_df = spark.read.csv(path='/shared/CS-GY-6513/parking-violations/parking-violations-header.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b31e8654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(summons_number='1307964308', issue_date='2016-03-07', violation_code='14', violation_county='NY', violation_description=None, violation_location='1', violation_precinct='1', violation_time='1040P', time_first_observed=None, meter_number='-', issuer_code='160307', issuer_command='0001', issuer_precinct='1', issuing_agency='K', plate_id='GBH2444', plate_type='PAS', registration_state='NY', street_name='N/S WARREN ST', vehicle_body_type='SDN', vehicle_color='BLACK', vehicle_make='HONDA', vehicle_year='2008'),\n",
       " Row(summons_number='1362655727', issue_date='2016-03-02', violation_code='98', violation_county='BX', violation_description=None, violation_location='45', violation_precinct='45', violation_time='0910P', time_first_observed=None, meter_number='-', issuer_code='945115', issuer_command='0043', issuer_precinct='43', issuing_agency='X', plate_id='GKZ2313', plate_type='PAS', registration_state='NY', street_name='PHILPS', vehicle_body_type='SUBN', vehicle_color='WHITE', vehicle_make='JEEP', vehicle_year='1999'),\n",
       " Row(summons_number='1363178234', issue_date='2016-03-01', violation_code='21', violation_county='NY', violation_description=None, violation_location='34', violation_precinct='34', violation_time='0836A', time_first_observed=None, meter_number='-', issuer_code='903530', issuer_command='MN12', issuer_precinct='0', issuing_agency='S', plate_id='N346594', plate_type='COM', registration_state='99', street_name='POST AVE', vehicle_body_type='SDN', vehicle_color='SILVE', vehicle_make='FORD', vehicle_year='0'),\n",
       " Row(summons_number='1365797030', issue_date='2016-03-02', violation_code='74', violation_county='K', violation_description=None, violation_location='67', violation_precinct='67', violation_time='1039P', time_first_observed=None, meter_number='-', issuer_code='952865', issuer_command='0067', issuer_precinct='67', issuing_agency='P', plate_id='GDP2624', plate_type='PAS', registration_state='NY', street_name='C/O E 53', vehicle_body_type='VAN', vehicle_color='WHITE', vehicle_make='DODGE', vehicle_year='1999'),\n",
       " Row(summons_number='1366529595', issue_date='2016-03-03', violation_code='38', violation_county='NY', violation_description=None, violation_location='14', violation_precinct='14', violation_time='0000A', time_first_observed=None, meter_number='-', issuer_code='954600', issuer_command='0161', issuer_precinct='161', issuing_agency='P', plate_id='42555JU', plate_type='COM', registration_state='NY', street_name='W 43 STREET', vehicle_body_type='VAN', vehicle_color='WHITE', vehicle_make='CHEVR', vehicle_year='2005')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check what the data looks like\n",
    "parking_df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6364866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember we can also use the SparkSQL interface\n",
    "parking_df.createOrReplaceTempView(\"parking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a35d48af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|plate_type|\n",
      "+----------+\n",
      "|       PAS|\n",
      "|       PAS|\n",
      "|       COM|\n",
      "|       PAS|\n",
      "|       COM|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT plate_type FROM parking\").show(5)\n",
    "#spark.sql(\"SELECT * FROM parking\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d12fc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1014017"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Duplicates\n",
    "# Values in the summons_number column must be unique - otherwise we have a key \n",
    "# constraint violation\n",
    "parking_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3d7590e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1014017"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# are the keys unique?\n",
    "parking_df.select('summons_number').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e045368d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13:======================================>                 (11 + 5) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|plate_type|\n",
      "+----------+\n",
      "|       CCK|\n",
      "|       CLG|\n",
      "|       NYA|\n",
      "|       SOS|\n",
      "|       SPC|\n",
      "|       SUP|\n",
      "|       OMO|\n",
      "|       LMB|\n",
      "|       APP|\n",
      "|       RGL|\n",
      "|       CHC|\n",
      "|       BOT|\n",
      "|       FAR|\n",
      "|       STA|\n",
      "|       COM|\n",
      "|       RGC|\n",
      "|       TRC|\n",
      "|       AMB|\n",
      "|       HAM|\n",
      "|       NYS|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's examine other attributes\n",
    "# Viewing Range of Values in a Column\n",
    "plate_type = spark.sql(\"SELECT DISTINCT plate_type FROM parking\")\n",
    "plate_type.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ffeb410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|count(DISTINCT plate_type)|\n",
      "+--------------------------+\n",
      "|                        75|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many distinct values are there\n",
    "spark.sql(\"SELECT count(DISTINCT plate_type) FROM parking\").show()\n",
    "# parking_df.select('plate_type').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cf149ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(plate_type='CCK'),\n",
       " Row(plate_type='CLG'),\n",
       " Row(plate_type='NYA'),\n",
       " Row(plate_type='SOS'),\n",
       " Row(plate_type='SPC'),\n",
       " Row(plate_type='SUP'),\n",
       " Row(plate_type='OMO'),\n",
       " Row(plate_type='LMB'),\n",
       " Row(plate_type='APP'),\n",
       " Row(plate_type='RGL'),\n",
       " Row(plate_type='CHC'),\n",
       " Row(plate_type='BOT'),\n",
       " Row(plate_type='FAR'),\n",
       " Row(plate_type='STA'),\n",
       " Row(plate_type='COM'),\n",
       " Row(plate_type='RGC'),\n",
       " Row(plate_type='TRC'),\n",
       " Row(plate_type='AMB'),\n",
       " Row(plate_type='HAM'),\n",
       " Row(plate_type='NYS'),\n",
       " Row(plate_type='BOB'),\n",
       " Row(plate_type='MCD'),\n",
       " Row(plate_type='CMH'),\n",
       " Row(plate_type='ORG'),\n",
       " Row(plate_type='IRP'),\n",
       " Row(plate_type='999')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plate_type.take(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc645d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|plate_type| COUNT|\n",
      "+----------+------+\n",
      "|       PAS|740554|\n",
      "|       COM|190147|\n",
      "|       OMT| 35480|\n",
      "|       OMS|  9032|\n",
      "|       SRF|  8341|\n",
      "|       IRP|  5291|\n",
      "|       999|  4467|\n",
      "|       TRC|  2784|\n",
      "|       OMR|  2158|\n",
      "|       APP|  1952|\n",
      "|       MOT|  1851|\n",
      "|       ORG|  1591|\n",
      "|       CMB|  1368|\n",
      "|       MED|  1211|\n",
      "|       OML|  1181|\n",
      "|       PSD|   900|\n",
      "|       SPO|   823|\n",
      "|       SCL|   700|\n",
      "|       TOW|   611|\n",
      "|       RGL|   524|\n",
      "+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the frequency distribution of the different plate types? i.e., plate type values and their counts\n",
    "\n",
    "spark.sql(\"SELECT plate_type,count(*) AS COUNT from parking group by plate_type \\\n",
    "order BY COUNT DESC\").show()\n",
    "\n",
    "# note how NULL values are represented in this dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ce69d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|plate_type| count|\n",
      "+----------+------+\n",
      "|       PAS|740554|\n",
      "|       COM|190147|\n",
      "|       OMT| 35480|\n",
      "|       OMS|  9032|\n",
      "|       SRF|  8341|\n",
      "|       IRP|  5291|\n",
      "|      null|  4467|\n",
      "|       TRC|  2784|\n",
      "|       OMR|  2158|\n",
      "|       APP|  1952|\n",
      "|       MOT|  1851|\n",
      "|       ORG|  1591|\n",
      "|       CMB|  1368|\n",
      "|       MED|  1211|\n",
      "|       OML|  1181|\n",
      "|       PSD|   900|\n",
      "|       SPO|   823|\n",
      "|       SCL|   700|\n",
      "|       TOW|   611|\n",
      "|       RGL|   524|\n",
      "|       VAS|   427|\n",
      "|       SRN|   348|\n",
      "|       DLR|   333|\n",
      "|       TRA|   318|\n",
      "|       ITP|   283|\n",
      "|       TRL|   223|\n",
      "+----------+------+\n",
      "only showing top 26 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 34:====================================================>   (15 + 1) / 16]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# change plate_type 999 to null\n",
    "from pyspark.sql import functions as F\n",
    "# create new dataframe with replaced values\n",
    "parking_df2 = parking_df.withColumn('plate_type', F.when(parking_df['plate_type']=='999', 'null').otherwise(parking_df['plate_type']))\n",
    "parking_df2.groupBy('plate_type').count().orderBy('count', ascending=False).show(26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0100679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|plate_type| count|\n",
      "+----------+------+\n",
      "|       PAS|740554|\n",
      "|       COM|190147|\n",
      "|       OMT| 35480|\n",
      "|       OMS|  9032|\n",
      "|       SRF|  8341|\n",
      "|       IRP|  5291|\n",
      "|       TRC|  2784|\n",
      "|       OMR|  2158|\n",
      "|       APP|  1952|\n",
      "|       MOT|  1851|\n",
      "|       ORG|  1591|\n",
      "|       CMB|  1368|\n",
      "|       MED|  1211|\n",
      "|       OML|  1181|\n",
      "|       PSD|   900|\n",
      "|       SPO|   823|\n",
      "|       SCL|   700|\n",
      "|       TOW|   611|\n",
      "|       RGL|   524|\n",
      "|       VAS|   427|\n",
      "|       SRN|   348|\n",
      "|       DLR|   333|\n",
      "|       TRA|   318|\n",
      "|       ITP|   283|\n",
      "|       TRL|   223|\n",
      "|       CMH|   203|\n",
      "+----------+------+\n",
      "only showing top 26 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if your analysis require a plate_type, you may want to\n",
    "# remove all rows where plate_type=999  (or null)\n",
    "parking_df3 = parking_df.filter(parking_df['plate_type']!='999')\n",
    "parking_df3.groupBy('plate_type').count().orderBy('count', ascending=False).show(26)\n",
    "parking_df3.select('plate_type').distinct().count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39015661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192974"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtering Rows with Blank Entries\n",
    "# exclude rows that have a blank entry in the violation_county column.\n",
    "parking_df.filter( parking_df[\"violation_county\"].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6979fcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "821043"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parking_df4 = parking_df.filter(parking_df['violation_county'].isNotNull())\n",
    "parking_df4.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40090989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:============================>                            (8 + 8) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:1014017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GBH2444',\n",
       " 'GKZ2313',\n",
       " 'N346594',\n",
       " 'GDP2624',\n",
       " '42555JU',\n",
       " '62636MD',\n",
       " 'DPE3045',\n",
       " 'FMW7832',\n",
       " 'DSD2130',\n",
       " '65111MB']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# “Clustering” helps detect entries in a column that are close together (and thus represent the same value\n",
    "\n",
    "plate_id_rdd = parking_df.select('plate_id').rdd.flatMap(list)\n",
    "print('Number of rows:' + str(plate_id_rdd.count()))\n",
    "plate_id_rdd.take(10)\n",
    "\n",
    "# a plate number may be represented in different ways, e.g.,\n",
    "# ('xbgv20', ['XBGV20', 'XBG.V20']),\n",
    "# ('ap717y', ['AP7!17Y', 'AP717Y']\n",
    "# this may be a problem if you want to find out, e.g., how many violations there are \n",
    "# for each plate number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab54c41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------------+----------------+---------------------+------------------+------------------+--------------+-------------------+------------+-----------+--------------+---------------+--------------+--------+----------+------------------+-----------+-----------------+-------------+------------+------------+\n",
      "|summons_number|issue_date|violation_code|violation_county|violation_description|violation_location|violation_precinct|violation_time|time_first_observed|meter_number|issuer_code|issuer_command|issuer_precinct|issuing_agency|plate_id|plate_type|registration_state|street_name|vehicle_body_type|vehicle_color|vehicle_make|vehicle_year|\n",
      "+--------------+----------+--------------+----------------+---------------------+------------------+------------------+--------------+-------------------+------------+-----------+--------------+---------------+--------------+--------+----------+------------------+-----------+-----------------+-------------+------------+------------+\n",
      "|    7009897037|2016-03-10|            53|              NY|       53-Safety Zone|                23|                23|         0137P|               null|        null|     361349|          T103|             23|             T| XBG.V20|       PAS|                NJ| E 106th St|             DELV|        WHITE|       FRUEH|           0|\n",
      "+--------------+----------+--------------+----------------+---------------------+------------------+------------------+--------------+-------------------+------------+-----------+--------------+---------------+--------------+--------+----------+------------------+-----------+-----------------+-------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * from parking where plate_id LIKE 'XBG.V20'\").show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b00be0c",
   "metadata": {},
   "source": [
    "\"Key Collision\" methods are based on the idea of creating a key value that contains only \n",
    " the most valuable or meaningful part of the string and groups together different strings based \n",
    " on the fact that their key is the same (hence the name \"key collision\").\n",
    "Fingerprinting Method:\n",
    "\n",
    "note that the order of these operations (the last 3 lines) is significant.\n",
    "remove leading and trailing whitespace\t\n",
    "change all characters to their lowercase representation\n",
    "remove all punctuation and control characters\n",
    "normalize extended western characters to their ASCII representation (for example \"gödel\" → \"godel\")\n",
    "split the string into whitespace-separated tokens\n",
    "sort the tokens and remove duplicates\n",
    "join the tokens back together\n",
    "\n",
    "(see details in https://openrefine.org/docs/manual/cellediting under Clustering Methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df418993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, unicodedata\n",
    "def fingerprint(value):\n",
    "    key = unicodedata.normalize('NFKD', value).encode('ascii','ignore').decode()\n",
    "    key = set(key.strip().lower().translate(str.maketrans('','',string.punctuation)).split())\n",
    "    key = ' '.join(sorted(list(key)))\n",
    "    return (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69b3293f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('xbgv20', 'XBG.V20')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's test the fingerprint function\n",
    "fingerprint('XBG.V20')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d721d96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('xbgv20', ['XBGV20', 'XBG.V20']),\n",
       " ('ap717y', ['AP7!17Y', 'AP717Y']),\n",
       " ('2970cp', ['2970.CP', '2970CP']),\n",
       " ('849rzb', ['849RZB.', '849RZB']),\n",
       " ('ab73725', ['AB.73725', 'AB73725']),\n",
       " ('47879mg', ['47879MG', '47879MG.']),\n",
       " ('12224mg', ['12224MG', '1222]4MG']),\n",
       " ('jhd0328', ['JHD0328.', 'JHD0328']),\n",
       " ('88cs02', ['88CS02', '88C.S02']),\n",
       " ('64582md', ['64582MD.', '64582MD']),\n",
       " ('l21687', ['L21687', 'L.21687']),\n",
       " ('na', ['N/A', 'NA']),\n",
       " ('u57afu', ['U57AFU', 'U57.AFU']),\n",
       " ('zxf293', ['ZXF293', 'ZXF293+']),\n",
       " ('6786cx', ['6786.CX', '6786CX']),\n",
       " ('zgk7779', ['ZGK7779', 'ZGK.7779']),\n",
       " ('jnp981', ['JNP981', 'JNP981&']),\n",
       " ('41690ja', ['41690JA', '41690JA+']),\n",
       " ('xt549k', ['XT.549K', 'XT549K']),\n",
       " ('hkv4504', ['HKV4504', 'HKV!4504']),\n",
       " ('7', ['7!', '7']),\n",
       " ('l08275', ['L08(275', 'L08275']),\n",
       " ('ete3059', ['ETE3059+', 'ETE3059']),\n",
       " ('l21741', ['L.21741', 'L21741']),\n",
       " ('jcw0303', ['JCW0303', 'JCW0303`']),\n",
       " ('aj511c', ['AJ511C', 'AJ.511C']),\n",
       " ('hcv1327', ['HCV1327', 'HCV!1327']),\n",
       " ('k90404', ['K90404', 'K.90404']),\n",
       " ('24787jz', ['24787JZ', '24787,JZ']),\n",
       " ('fcz8588', ['FCZ!8588', 'FCZ8588']),\n",
       " ('smutty', ['SMUTTY+', 'SMUTTY']),\n",
       " ('1mdm', ['1MDM', '#1MDM']),\n",
       " ('ns', ['NS', 'N/S'])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plate_id_rdd. \\\n",
    "\tdistinct().map(fingerprint). \\\n",
    "\tgroupByKey(). \\\n",
    "\tfilter(lambda x: len(x[1])>1). \\\n",
    "\tmapValues(list). \\\n",
    "\tcollect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e6151e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------------+----------------+---------------------+------------------+------------------+--------------+-------------------+------------+-----------+--------------+---------------+--------------+--------+----------+------------------+---------------+-----------------+-------------+------------+------------+\n",
      "|summons_number|issue_date|violation_code|violation_county|violation_description|violation_location|violation_precinct|violation_time|time_first_observed|meter_number|issuer_code|issuer_command|issuer_precinct|issuing_agency|plate_id|plate_type|registration_state|    street_name|vehicle_body_type|vehicle_color|vehicle_make|vehicle_year|\n",
      "+--------------+----------+--------------+----------------+---------------------+------------------+------------------+--------------+-------------------+------------+-----------+--------------+---------------+--------------+--------+----------+------------------+---------------+-----------------+-------------+------------+------------+\n",
      "|    7081878969|2016-03-10|            48|              BX|         48-Bike Lane|                40|                40|         1019A|               null|        null|     358609|          T201|             40|             T|  2970CP|       COM|                CT|    Melrose Ave|             PICK|          TAN|        FORD|           0|\n",
      "|    7191964236|2016-03-04|            38|              BX| 38-Failure to Dis...|                47|                47|         0254P|               null|        null|     363080|          T201|             47|             T|  2970CP|       999|                CT|      Boston Rd|             PICK|        WHITE|        FORD|           0|\n",
      "|    7417510589|2016-03-16|            46|              BX| 46B-Double Parkin...|                44|                44|         0356P|              1200P|        null|     361796|          T201|             44|             T|  2970CP|       CMB|                CT|Grand Concourse|              VAN|        WHITE|        FORD|           0|\n",
      "|    7554375489|2016-03-08|            46|              BX| 46B-Double Parkin...|                45|                45|         1055A|              1050A|        null|     362268|          T201|             45|             T| 2970.CP|       CMB|                CT|  E Tremont Ave|             PICK|        WHITE|        FORD|           0|\n",
      "|    7637915049|2016-03-15|            37|              BX| 37-Expired Muni M...|                43|                43|         0421P|              0415P|    217-3200|     363079|          T201|             43|             T|  2970CP|       999|                CT|        Wood Rd|             PICK|        WHITE|        FORD|           0|\n",
      "+--------------+----------+--------------+----------------+---------------------+------------------+------------------+--------------+-------------------+------------+-----------+--------------+---------------+--------------+--------+----------+------------------+---------------+-----------------+-------------+------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 64:==============================================>          (9 + 2) / 11]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# To determine whether a cluster should be merged or not, you can look more closely \n",
    "# at the data.\n",
    "# Check the other attributes to determine if the two ids correspond to the same entity\n",
    "parking_df.where((parking_df.plate_id == '2970CP') | \\\n",
    "\t(parking_df.plate_id == '2970.CP')). \\\n",
    "\tshow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1de73617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------------+----------------+---------------------+------------------+------------------+--------------+-------------------+------------+-----------+--------------+---------------+--------------+--------+----------+------------------+-----------+-----------------+-------------+------------+------------+\n",
      "|summons_number|issue_date|violation_code|violation_county|violation_description|violation_location|violation_precinct|violation_time|time_first_observed|meter_number|issuer_code|issuer_command|issuer_precinct|issuing_agency|plate_id|plate_type|registration_state|street_name|vehicle_body_type|vehicle_color|vehicle_make|vehicle_year|\n",
      "+--------------+----------+--------------+----------------+---------------------+------------------+------------------+--------------+-------------------+------------+-----------+--------------+---------------+--------------+--------+----------+------------------+-----------+-----------------+-------------+------------+------------+\n",
      "|    7066709810|2016-03-01|            46|              NY| 46B-Double Parkin...|                 1|                 1|         0234P|              1200P|        null|     362546|          T105|              1|             T| L.21687|       CMB|                CT| W Broadway|             DELV|        YELLO|        HINO|           0|\n",
      "|    7369714214|2016-03-12|            85|               K| 85-Storage-3 hour...|                79|                79|         0952A|              0600A|        null|     347663|          T301|             79|             T|  L21687|       CMB|                CT| Ryerson St|              VAN|        YELLO|       NS/OT|           0|\n",
      "|    7369719492|2016-03-26|            85|               K| 85-Storage-3 hour...|                79|                79|         1103A|              0600A|        null|     347663|          T301|             79|             T|  L21687|       APP|                CT| Ryerson St|              VAN|        YELLO|       NS/OT|           0|\n",
      "|    7499574969|2016-03-15|            14|              NY|       14-No Standing|                20|                20|         0234P|               null|        null|     356259|          T103|             20|             T|  L21687|       COM|                CT|  W 61st St|             DELV|        OTHER|        HINO|           0|\n",
      "|    7499578320|2016-03-30|            14|              NY|       14-No Standing|                20|                20|         0429P|               null|        null|     356259|          T103|             20|             T|  L21687|       COM|                CT|  W 61st St|             DELV|        YELLO|        HINO|           0|\n",
      "+--------------+----------+--------------+----------------+---------------------+------------------+------------------+--------------+-------------------+------------+-----------+--------------+---------------+--------------+--------+----------+------------------+-----------+-----------------+-------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parking_df.where((parking_df.plate_id == 'L21687') | \\\n",
    "\t(parking_df.plate_id == 'L.21687')). \\\n",
    "\tshow()\n",
    "\n",
    "# By looking at other attributes such as vehicle_body_type  (DELV vs Van) and vehicle_make (HINO, NS/OT), \n",
    "# it seems that these are not the same (maybe not an error).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2c41350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22893"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making Text Consistent \n",
    "# clustering on the street_name column\n",
    "street_name_rdd = parking_df.select('street_name').distinct().rdd.flatMap(list).filter(lambda x: x!=None)\n",
    "street_name_rdd.count()\n",
    "\n",
    "# lots of distinct street names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ddb3b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COURT SQUARE', 'E 31 ST', 'RANDALLS ISLAND', 'E 45TH STREET', 'SHERIDAN AVE']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street_name_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9b85fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2756"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's use the fingerprint function to make the street names more consistent\n",
    "stname_clusters = street_name_rdd.map(fingerprint). \\\n",
    "\tgroupByKey(). \\\n",
    "\tfilter(lambda x: len(x[1])>1). \\\n",
    "\tmapValues(list)\n",
    "\n",
    "\n",
    "# after applying the fingerprint function, we go from 22,893 distinct street names to 2,756\n",
    "stname_clusters.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9614879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fernside pl', ['FERNSIDE PL', 'Fernside Pl']),\n",
       " ('astor pl', ['Astor Pl', 'ASTOR PL']),\n",
       " ('bedford blvd park', ['Bedford Park Blvd', 'BEDFORD PARK BLVD']),\n",
       " ('44th e st', ['E 44th St', 'E 44TH ST']),\n",
       " ('223rd pl', ['223rd Pl', '223RD PL'])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stname_clusters.take(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d51099e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of normalized streets:19949\n"
     ]
    }
   ],
   "source": [
    "# Now normalize the actual data\n",
    "stname_normalized = street_name_rdd.map(fingerprint).map(lambda x: x[0])\n",
    "print(\"Number of normalized streets:\" + str(stname_normalized.distinct().count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "90c938db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['court square', '31 e st', 'island randalls', '45th e street', 'ave sheridan']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stname_normalized.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9a9ccca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['31 e st', '45th e street', '87 nb st', '110 st w', '129 co st']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter streets that contain \"st\"\n",
    "stname_normalized.filter(lambda x: x if \"st\" in x else \"\").take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20aa175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to cluster the vehicle_color column. This clustering method is not so effective for this column. \n",
    "# You could try to use k-nearest neighbors algorithm \n",
    "# (see https://github.com/OpenRefine/OpenRefine/wiki/Clustering-In-Depth ) \n",
    "# Remember, different similarity functions can be used depending on the data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
