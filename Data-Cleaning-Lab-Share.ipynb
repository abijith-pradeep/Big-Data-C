{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af42f848",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkContext, SparkConf\n\u001b[0;32m      2\u001b[0m cf \u001b[38;5;241m=\u001b[39m SparkConf()\n\u001b[0;32m      3\u001b[0m cf\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.submit.deployMode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "cf = SparkConf()\n",
    "cf.set(\"spark.submit.deployMode\",\"client\")\n",
    "sc = SparkContext.getOrCreate(cf)\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "\t    .builder \\\n",
    "\t    .appName(\"Python Spark SQL basic example\") \\\n",
    "\t    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "\t    .getOrCreate()\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d11d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "parking_df = spark.read.csv(path='/shared/CS-GY-6513/parking-violations/parking-violations-header.csv',header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d12fc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1014017"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parking_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3d7590e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1014017"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parking_df.select('summons_number').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "897cfe93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|count(DISTINCT plate_type)|\n",
      "+--------------------------+\n",
      "|                        75|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "parking_df.createOrReplaceTempView(\"parking\")\n",
    "spark.sql(\"SELECT count(DISTINCT plate_type) FROM parking\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e045368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the distinct plate types in the table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc645d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List each distinct plate type and its frequency in the table\n",
    "# e.g.\n",
    "#    plate_type count\n",
    "#    PAS        740554\n",
    "#    COM        190147\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4617eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order the results of the previous query by count, the most frequent should appear first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce69d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|plate_type| count|\n",
      "+----------+------+\n",
      "|       PAS|740554|\n",
      "|       COM|190147|\n",
      "|       OMT| 35480|\n",
      "|       OMS|  9032|\n",
      "|       SRF|  8341|\n",
      "|       IRP|  5291|\n",
      "|      null|  4467|\n",
      "|       TRC|  2784|\n",
      "|       OMR|  2158|\n",
      "|       APP|  1952|\n",
      "|       MOT|  1851|\n",
      "|       ORG|  1591|\n",
      "|       CMB|  1368|\n",
      "|       MED|  1211|\n",
      "|       OML|  1181|\n",
      "|       PSD|   900|\n",
      "|       SPO|   823|\n",
      "|       SCL|   700|\n",
      "|       TOW|   611|\n",
      "|       RGL|   524|\n",
      "|       VAS|   427|\n",
      "|       SRN|   348|\n",
      "|       DLR|   333|\n",
      "|       TRA|   318|\n",
      "|       ITP|   283|\n",
      "|       TRL|   223|\n",
      "+----------+------+\n",
      "only showing top 26 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change plate_type 999 to null\n",
    "from pyspark.sql import functions as F\n",
    "parking_df2 = parking_df.withColumn('plate_type', F.when(parking_df['plate_type']=='999', 'null').otherwise(parking_df['plate_type']))\n",
    "parking_df2.groupBy('plate_type').count().orderBy('count', ascending=False).show(26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0100679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows where plate_type=999  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39015661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192974"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppose we are interested in analyzing violations based on what county they occur.\n",
    "# We might want to exclude rows that have a blank entry in the violation_county column.\n",
    "# How many rows have Blank Entries in violation_county?\n",
    "parking_df.filter( parking_df[\"violation_county\"].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6979fcf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4293702517.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [13]\u001b[0;36m\u001b[0m\n\u001b[0;31m    parking_df4 =\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataframe without any black entries in violation_county\n",
    "parking_df4 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40090989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GBH2444',\n",
       " 'GKZ2313',\n",
       " 'N346594',\n",
       " 'GDP2624',\n",
       " '42555JU',\n",
       " '62636MD',\n",
       " 'DPE3045',\n",
       " 'FMW7832',\n",
       " 'DSD2130',\n",
       " '65111MB',\n",
       " 'GMZ3750',\n",
       " '44884',\n",
       " 'XZ876G',\n",
       " 'PIKINE',\n",
       " 'GMU4296',\n",
       " 'GEJ8235',\n",
       " '74452JW',\n",
       " '42972JW',\n",
       " '66951',\n",
       " '63400JM',\n",
       " 'GGS5172',\n",
       " '51329A',\n",
       " '49216KA',\n",
       " '31695JZ',\n",
       " '79638KA',\n",
       " '88720MB',\n",
       " 'ERP5344',\n",
       " 'FWM1758',\n",
       " '14307LV',\n",
       " 'EWT1353',\n",
       " '65566PA',\n",
       " 'FPF5158',\n",
       " '24393MC',\n",
       " '24393MG',\n",
       " 'FXR1798',\n",
       " 'FWH9893',\n",
       " '88629JH',\n",
       " '1510332',\n",
       " 'DJE1615',\n",
       " '2208656',\n",
       " 'GXC7520',\n",
       " 'GRC4443',\n",
       " 'T639084C',\n",
       " 'GARFR5',\n",
       " 'GTJ6780',\n",
       " '401ZGU',\n",
       " 'ZWF21Z',\n",
       " 'S274036',\n",
       " 'PF090W',\n",
       " 'GLR6718']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's clean the plate_ids\n",
    "# “Clustering” helps detect entries in a column that are close together (and thus represent the same value\n",
    "\n",
    "plate_id_rdd = parking_df.select('plate_id').rdd.flatMap(list)\n",
    "plate_id_rdd.take(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79190cfd",
   "metadata": {},
   "source": [
    "\"Key Collision\" methods are based on the idea of creating a key value that contains only \n",
    " the most valuable or meaningful part of the string and groups together different strings based \n",
    " on the fact that their key is the same (hence the name \"key collision\").\n",
    "Fingerprinting Method:\n",
    "note that the order of these operations (the last 3 lines) is significant.\n",
    "remove leading and trailing whitespace\t\n",
    "change all characters to their lowercase representation\n",
    "remove all punctuation and control characters\n",
    "normalize extended western characters to their ASCII representation (for example \"gödel\" → \"godel\")\n",
    "split the string into whitespace-separated tokens\n",
    "sort the tokens and remove duplicates\n",
    "join the tokens back together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df418993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, unicodedata\n",
    "def fingerprint(value):\n",
    "    key = unicodedata.normalize('NFKD', value).encode('ascii','ignore').decode()\n",
    "    key = set(key.strip().lower().translate(str.maketrans('','',string.punctuation)).split())\n",
    "    key = ' '.join(sorted(list(key)))\n",
    "    return (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69b3293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('gkz2313', 'GKZ2313')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plate_id_rdd.distinct().map(fingerprint).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d721d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the fingerprint function to all plate_id values, and group the ones\n",
    "# that have the same key\n",
    "# mapValues(list) - makes the grouped values into a list\n",
    "plate_id_rdd.distinct(). \\\n",
    "\tmap(fingerprint). \\\n",
    "\tgroupByKey(). \\\n",
    "\tfilter(lambda x: len(x[1])>1). \\\n",
    "\tmapValues(list). \\\n",
    "\tcollect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2331c64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('2970cp', <pyspark.resultiterable.ResultIterable at 0x7f31d918a6a0>),\n",
       " ('ap717y', <pyspark.resultiterable.ResultIterable at 0x7f31d918adf0>),\n",
       " ('xbgv20', <pyspark.resultiterable.ResultIterable at 0x7f31d918ad60>),\n",
       " ('849rzb', <pyspark.resultiterable.ResultIterable at 0x7f31d9185820>),\n",
       " ('ab73725', <pyspark.resultiterable.ResultIterable at 0x7f31d9185130>)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plate_id_rdd.distinct(). \\\n",
    "\tmap(fingerprint). \\\n",
    "\tgroupByKey(). \\\n",
    "\tfilter(lambda x: len(x[1])>1).take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6151e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To determine a cluster should be merged or not, you can look more closely at the data.\n",
    "# check the other attributes to determine if the two ids correspond to the same entity\n",
    "parking_df.where((parking_df.plate_id == '2970CP') | \\\n",
    "\t(parking_df.plate_id == '2970.CP')). \\\n",
    "\tshow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c41350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering on the street_name column.\n",
    "street_name_rdd = parking_df.select('street_name').distinct().rdd.flatMap(list).filter(lambda x: x!=None)\n",
    "\n",
    "stname_clusters = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9614879",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_name_rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51099e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the fingerprint to all street addresses\n",
    "#[('court square', 'COURT SQUARE'),\n",
    "# ('31 e st', 'E 31 ST'),\n",
    "# ('island randalls', 'RANDALLS ISLAND'),\n",
    "# ('45th e street', 'E 45TH STREET'),\n",
    "# ('ave sheridan', 'SHERIDAN AVE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a476f3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73ac9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05860e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9ccca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20aa175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
